from google.colab import drive
drive.mount('/content/drive')

#-------------------------------------------------------------------------------------------------------
import os
from pathlib import Path
import shutil


src_data_dir = "      " # add your dataset path


base_dir = "/content/PatternSenseSplit"
train_dir = os.path.join(base_dir, "train")
val_dir = os.path.join(base_dir, "val")


shutil.rmtree(base_dir, ignore_errors=True)
os.makedirs(train_dir), os.makedirs(val_dir)

# Split into 80% train, 20% val
import random
from glob import glob

class_names = os.listdir(src_data_dir)
for cls in class_names:
    imgs = glob(f"{src_data_dir}/{cls}/*")
    random.shuffle(imgs)
    split_point = int(len(imgs) * 0.8)
    train_imgs = imgs[:split_point]
    val_imgs = imgs[split_point:]

    os.makedirs(f"{train_dir}/{cls}", exist_ok=True)
    os.makedirs(f"{val_dir}/{cls}", exist_ok=True)

    for img in train_imgs:
        shutil.copy(img, f"{train_dir}/{cls}")
    for img in val_imgs:
        shutil.copy(img, f"{val_dir}/{cls}")

print("âœ… Dataset split complete.")

#-------------------------------------------------------------------------------------------------------
import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau

# Image size and batch
img_size = 224
batch_size = 16


train_gen = ImageDataGenerator(rescale=1./255, rotation_range=20,
                               width_shift_range=0.2, height_shift_range=0.2,
                               shear_range=0.1, zoom_range=0.2, horizontal_flip=True)
val_gen = ImageDataGenerator(rescale=1./255)

train_data = train_gen.flow_from_directory(train_dir, target_size=(img_size, img_size),
                                           class_mode='categorical', batch_size=batch_size)
val_data = val_gen.flow_from_directory(val_dir, target_size=(img_size, img_size),
                                       class_mode='categorical', batch_size=batch_size)

# Base model
base_model = MobileNetV2(include_top=False, input_shape=(img_size, img_size, 3), weights='imagenet')
base_model.trainable = False

x = GlobalAveragePooling2D()(base_model.output)
x = Dropout(0.3)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.3)(x)
output = Dense(10, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
model.summary()

#-------------------------------------------------------------------------------------------------------

callbacks = [
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
    ReduceLROnPlateau(patience=2, factor=0.5),
    ModelCheckpoint("psm_best_model.h5", save_best_only=True)
]

history = model.fit(
    train_data,
    validation_data=val_data,
    epochs=30,
    callbacks=callbacks
)

---------------------------------------------------------------------------------------------


base_model.trainable = True
for layer in base_model.layers[:-30]:
    layer.trainable = False


model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),
              loss='categorical_crossentropy', metrics=['accuracy'])

# Fine-tune
model.fit(
    train_data,
    validation_data=val_data,
    epochs=10,
    callbacks=callbacks
)



""" Your model will be saved as   psm_best_model.h5    """
